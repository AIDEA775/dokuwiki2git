#!/usr/bin/env python
# Copyright (c) 2011-2014 Heikki Hokkanen <hoxu at users.sf.net>
# License: AGPLv3
import argparse
import fnmatch
import logging
import json
import os
import subprocess
import sys
import time

logging.basicConfig(level = logging.DEBUG, format = '%(levelname)s - %(message)s')
log = logging.getLogger()

class Converter:
	def __init__(self):
		self.args = None # arguments from the command line
		self.dwdata = {} # setting data loaded from the dokuwiki
		self.users = {} # user data loaded from the dokuwiki
		self.changelog = [] # gross change list, each item is ([date, ip, type, id, user, sum, extra], itemid, itemtype, itemextra)
		self.changes = { 'page': {}, 'media': {} } # per-id change list, { itemtype: { id: [date, ip, type, id, user, sum, extra] } }
		self.commands = [] # shell commands to run
		self.since = '' # timestamp to start import

	def create_git_repository(self):
		log.info('Importing to git')
		origdir = os.getcwd()
		if not os.path.exists(self.args.outputdir):
			os.mkdir(self.args.outputdir)
		os.chdir(self.args.outputdir)
		# run all commands
		for c in self.commands:
			log.debug('CMD: %s' % c)
			ret = subprocess.call(c, shell=True)
			if ret != 0:
				raise RuntimeError('Command "%s" failed' % c)
		os.chdir(origdir)

	def read_attic(self):

		def get_source_file(itemtype, subpath, timestamp):
			if itemtype == 'page':
				# try attic/ folder for each compression types
				filename = os.path.join(self.dwdata['conf']['olddir'].encode('UTF-8'), '%s.%s.txt' % (subpath, timestamp))
				if os.path.exists(filename): return filename
				filename = os.path.join(self.dwdata['conf']['olddir'].encode('UTF-8'), '%s.%s.txt.gz' % (subpath, timestamp))
				if os.path.exists(filename): return filename
				filename = os.path.join(self.dwdata['conf']['olddir'].encode('UTF-8'), '%s.%s.txt.bz2' % (subpath, timestamp))
				if os.path.exists(filename): return filename
				# try pages/ folder
				filename = os.path.join(self.dwdata['conf']['datadir'].encode('UTF-8'), '%s.txt' % subpath)
				if os.path.exists(filename) and str(int(os.path.getmtime(filename))) == timestamp: return filename
				# not exist, error out
				log.warn('Attic file of page "%s" with timestamp "%s" is missing' % (subpath, timestamp))
				return None
			elif itemtype == 'media':
				parts = os.path.splitext(subpath)
				# try media_attic/ folder
				filename = os.path.join(self.dwdata['conf']['mediaolddir'].encode('UTF-8'), '%s.%s%s' % (parts[0], timestamp, parts[1]))
				if os.path.exists(filename): return filename
				# try media/ folder
				filename = os.path.join(self.dwdata['conf']['mediadir'].encode('UTF-8'), '%s%s' % (parts[0], parts[1]))
				if os.path.exists(filename) and str(int(os.path.getmtime(filename))) == timestamp: return filename
				# not exist, error out
				log.warn('Attic file of media "%s" with timestamp "%s" is missing' % (subpath, timestamp))
				return None

		def add_commit(c, itemid, itemtype, itemextra):

			def pack_notes(notes):
				list = []
				for (key, value) in notes:
					list.append('%s: %s' % (key, json.dumps(value, ensure_ascii=False)))
				return '\n'.join(list)

			# init notes
			notes = [] # [ [key1, value2], [key2, value2], ... ]
			notes.append(['log', c])
			if 'external edit auto-detected' in itemextra:
				notes.append(['info', 'external edit auto-detected'])
			# init variables
			timestamp, ip, type, id, user, message, extra = c
			if timestamp < self.since: return
			if id != itemid:
				log.warn('Log of %s "%s" records id "%s" at timestamp %s, resolve as if it has been %s' % (itemtype, itemid, id, timestamp, itemid))
				id = itemid
			subpath = id.replace(':', '/')
			source_file = get_source_file(itemtype, subpath, timestamp)
			# author (user <email>)
			email = self.args.site_mail
			if len(user) == 0:
				user = ip
			elif user in self.users:
				email = self.users[user]['email']
				user = self.users[user]['name']
			author = '%s <%s>' % (user, email)
			# message
			if itemtype == 'page':
				message = '%s: %s' % (subpath, message)
			elif itemtype == 'media':
				message = '(media) %s: %s' % (subpath, message)
			# target_file
			if itemtype == 'page':
				target_file = os.path.join('pages', '%s.txt' % subpath)
			elif itemtype == 'media':
				target_file = os.path.join('media', subpath)
			# build commands
			cmds = []
			if type in ('C', 'E', 'e', 'R'): # create, edit, minor edit, restore
				dirname = os.path.dirname(target_file)
				if len(dirname) > 0:
					cmds.append('mkdir -p %s' % self.shell_quote(dirname))
				if source_file is not None:
					if itemtype == 'page':
						if fnmatch.fnmatch(source_file, '*.txt'):
							cmds.append('cp -a %s %s' % (self.shell_quote(source_file), self.shell_quote(target_file)))
						elif fnmatch.fnmatch(source_file, '*.txt.gz'):
							cmds.append('gunzip -c %s > %s' % (self.shell_quote(source_file), self.shell_quote(target_file)))
						elif fnmatch.fnmatch(source_file, '*.txt.bz2'):
							cmds.append('bunzip2 -c %s > %s' % (self.shell_quote(source_file), self.shell_quote(target_file)))
					elif itemtype == 'media':
						cmds.append('cp -a %s %s' % (self.shell_quote(source_file), self.shell_quote(target_file)))
				else:
					# flush a unique dummy content reather than remove the file, so that "git log -- file" can trace easily
					cmds.append('echo "content missing after commit: $(git rev-parse --verify -q HEAD || echo "0000000000000000000000000000000000000000")" > %s' % (self.shell_quote(target_file)))
					notes.append(['info', 'attic missing'])
				cmds.append('git add %s' % self.shell_quote(target_file))
			elif type == 'D': # delete
				cmds.append('git rm --quiet --ignore-unmatch %s' % self.shell_quote(target_file))
			cmds.append('git commit --quiet --allow-empty --allow-empty-message --author=%s --date=%s -m %s' % (self.shell_quote(author), self.shell_quote(timestamp), self.shell_quote(message)))
			cmds.append('git notes --ref=%s add -m %s' % (self.shell_quote(self.args.notes_ref), self.shell_quote(pack_notes(notes))))
			self.commands.extend(cmds)

		log.info('Reading attic')
		for (c, itemid, itemtype, itemextra) in self.changelog:
			add_commit(c, itemid, itemtype, itemextra)

	def check_attic(self):

		def check_changelog_entry(itemtype, subpath, timestamp):
			id = subpath.replace('/', ':')
			dict = self.changes[itemtype]
			if id in dict:
				for c in dict[id]:
					if timestamp == c[0] and id == c[3]:
						return
			log.warn('Attic file of %s "%s" with timestamp %s is not referenced by the changelog' % (itemtype, id, timestamp))

		log.info('Checking attic')
		root = self.dwdata['conf']['olddir'].encode('UTF-8')
		itemtype = 'page'
		for path, dirs, files in os.walk(root):
			for f in files:
				if fnmatch.fnmatch(f, '_*'): continue
				if fnmatch.fnmatch(f, '*.txt') or fnmatch.fnmatch(f, '*.txt.gz') or fnmatch.fnmatch(f, '*.txt.bz2'):
					fullpath = os.path.join(path, f)
					subpath = os.path.relpath(fullpath, root)
					if fnmatch.fnmatch(fullpath, '*.txt'):
						subpath, timestamp, txt = subpath.rsplit('.', 2)
					else:
						subpath, timestamp, txt, zip = subpath.rsplit('.', 3)
					check_changelog_entry(itemtype, subpath, timestamp)

		log.info('Checking media_attic')
		root = self.dwdata['conf']['mediaolddir'].encode('UTF-8')
		itemtype = 'media'
		for path, dirs, files in os.walk(root):
			for f in files:
				if fnmatch.fnmatch(f, '_*'): continue
				fullpath = os.path.join(path, f)
				subpath = os.path.relpath(fullpath, root)
				subpath0, timestamp, subpath1 = subpath.rsplit('.', 2)
				subpath = '%s.%s' % (subpath0, subpath1)
				check_changelog_entry(itemtype, subpath, timestamp)

	def read_meta(self):

		def read_meta_file(itemtype, subpath, fullpath):
			id = subpath.replace('/', ':')
			log.debug('Reading meta for %s "%s"' % (itemtype, id))
			with open(fullpath, 'rb') as f:
				for line in f:
					line = line.rstrip('\n')
					if len(line) == 0: continue
					changeparts = line.split('\t')
					log.debug(changeparts)
					assert(len(changeparts) == 7)
					assert(changeparts[2] in ('C', 'D', 'E', 'e', 'R')) # create, delete, edit, minor edit, restore
					entry = (changeparts, id, itemtype, {})
					self.changelog.append(entry)
					dict = self.changes[itemtype]
					if id not in dict: dict[id] = []
					dict[id].append(changeparts)

		log.info('Reading meta')
		root = self.dwdata['conf']['metadir'].encode('UTF-8')
		itemtype = 'page'
		items = 0
		for path, dirs, files in os.walk(root):
			for f in files:
				if fnmatch.fnmatch(f, '_*'): continue
				if fnmatch.fnmatch(f, '*.changes'):
					fullpath = os.path.join(path, f)
					subpath = os.path.splitext(os.path.relpath(fullpath, root))[0]
					read_meta_file(itemtype, subpath, fullpath)
					items += 1
		logs = len(self.changelog)
		log.info('%d changelog entries for %d pages found' % (logs, items))

		log.info('Reading media_meta')
		root = self.dwdata['conf']['mediametadir'].encode('UTF-8')
		itemtype = 'media'
		items = 0
		for path, dirs, files in os.walk(root):
			for f in files:
				if fnmatch.fnmatch(f, '_*'): continue
				if fnmatch.fnmatch(f, '*.changes'):
					fullpath = os.path.join(path, f)
					subpath = os.path.splitext(os.path.relpath(fullpath, root))[0]
					read_meta_file(itemtype, subpath, fullpath)
					items += 1
		logs = len(self.changelog) - logs
		log.info('%d changelog entries for %d media found' % (logs, items))

	def read_pages_and_media(self):

		def last_changelog_entry(itemtype, id):
			dict = self.changes[itemtype]
			if id in dict:
				return dict[id][-1]
			return None

		log.info('Reading pages/ for possible external edits')
		root = self.dwdata['conf']['datadir'].encode('UTF-8')
		itemtype = 'page'
		items = 0
		for path, dirs, files in os.walk(root):
			for f in files:
				if fnmatch.fnmatch(f, '_*'): continue
				if fnmatch.fnmatch(f, '*.txt'):
					filename = os.path.join(path, f)
					id = os.path.splitext(os.path.relpath(filename, root))[0].replace('/', ':')
					timestamp = str(int(os.path.getmtime(filename)))
					c = last_changelog_entry(itemtype, id) # [date, ip, type, id, user, sum, extra]
					# if the page is not in meta or the page has newer change, create a log as an external edit
					if c is None or c[0] < timestamp:
						type = 'C' if c is None or c[2] == 'D' else 'E'
						changeparts = [timestamp, '127.0.0.1', type, id, '', self.dwdata['lang']['external_edit'].encode('UTF-8'), '']
						log.debug(changeparts)
						entry = (changeparts, id, itemtype, {'external edit auto-detected':True})
						self.changelog.append(entry)
						items += 1
		log.info('%d newly edited pages found' % (items))

		log.info('Reading media/ for possible external edits')
		root = self.dwdata['conf']['mediadir'].encode('UTF-8')
		itemtype = 'media'
		items = 0
		for path, dirs, files in os.walk(root):
			for f in files:
				if fnmatch.fnmatch(f, '_*'): continue
				if True:
					filename = os.path.join(path, f)
					id = os.path.relpath(filename, root).replace('/', ':')
					timestamp = str(int(os.path.getmtime(filename)))
					c = last_changelog_entry(itemtype, id) # [date, ip, type, id, user, sum, extra]
					# if the media is not in meta or the page has newer change, create a log as an external edit
					if c is None or c[0] < timestamp:
						type = 'C' if c is None or c[2] == 'D' else 'E'
						changeparts = [timestamp, '127.0.0.1', type, id, '', self.dwdata['lang']['external_edit'].encode('UTF-8'), '']
						log.debug(changeparts)
						entry = (changeparts, id, itemtype, {'external edit auto-detected':True})
						self.changelog.append(entry)
						items += 1
		log.info('%d newly edited media found' % (items))

	def read_user_data(self):
		# check if requested and available
		if not self.args.import_user:
			return
		elif self.dwdata['conf']['authtype'] != 'authplain':
			log.warn('The dokuwiki doesn\'t support plain auth, skip loading and importing users data')
			return
		log.info('Reading users.auth.php')
		users_file = self.dwdata['config_cascade']['plainauth.users']['default'].encode('UTF-8')
		with open(users_file, 'rb') as f:
			for line in f:
				if not line.startswith("#") and len(line) > 1:
					userparts = line.split(':')
					assert(len(userparts) == 5)
					log.debug(userparts)
					self.users[userparts[0]] = {'name' : userparts[2], 'email': userparts[3]}
		log.info('Read %d users' % len(self.users))

	def run(self, params):
		parser = argparse.ArgumentParser(
			prog='dokuwiki2git',
			description='''dokuwiki2git converts dokuwiki data directory into a git repository containing the wiki pages, with proper history. Thus, migration to git-backed wiki engines (eg. gollum) becomes easier.''')
		parser.add_argument('-i', '--incremental', action='store_true', dest='incremental', help='''import only the changes since the HEAD author date if a git repo already exists''')
		parser.add_argument('-o', '--output', dest='outputdir', default = 'gitdir', metavar='<output dir>', help='''directory to create the git repo (default: %(default)s)''')
		parser.add_argument('-u', '--users', dest='import_user', action='store_true', help='''record real user name and email in the author field of each commit''')
		parser.add_argument('-m', '--site-mail', dest='site_mail', default='dokuwiki@localhost', metavar='<text>', action='store', help='''the dummy email address to be recorded as the author email if it's not available''')
		parser.add_argument('-e', '--external-edit', action='store_true', dest='external_edit', help='''import external edits not recorded in meta .changes''')
		parser.add_argument('-q', '--quiet', action='store_const', dest='verbose', const=0, default=1, help='''show only warnings and errors''')
		parser.add_argument('-v', '--verbose', action='store_const', dest='verbose', const=2, default=1, help='''show debug messages''')
		parser.add_argument('--notes-ref', metavar='<notes ref>', action='store', dest='notes_ref', default='refs/notes/dokuwiki2git', help='''record the import information to this ref (default: %(default)s)''')
		parser.add_argument('dwdir', metavar='<dokuwiki dir>', help='''path to dokuwiki''')

		# parse arguments
		self.args = args = parser.parse_args(params)
		log.setLevel((logging.WARN, logging.INFO, logging.DEBUG)[args.verbose])

		time_start = time.time()
		log.info('Import data from dokuwiki "%s" at "%s"' % (args.dwdir, args.site_mail))

		# check and load dokuwiki data
		try:
			self.dwdata = json.loads(subprocess.check_output('php dokuwiki.php %s' % self.shell_quote(args.dwdir), shell=True))
		except:
			log.error('Unable to read php scripts from the specified dokuwiki directory')
			sys.exit(1)
		# check output directory
		if os.path.exists(args.outputdir):
			if args.incremental:
				# check whether the output directory is a valid git repo
				# currently we don't support a bare repo
				try:
					gitdir = os.path.join(args.outputdir, '.git')
					assert(os.path.exists(gitdir))
					subprocess.check_output('git --git-dir %s rev-parse --git-dir 2>/dev/null' % self.shell_quote(gitdir), shell=True)
				except:
					log.error('The specified output directory is not a valid git repository "%s"' % args.outputdir)
					sys.exit(1)
				# record the last author date from the active branch if it has at least one commit
				try:
					self.since = subprocess.check_output('git --git-dir %s log -n 1 --pretty="format:%%at" 2>/dev/null' % self.shell_quote(gitdir), shell=True)
					log.info('Import data since %s' % self.since)
				except:
					pass
			else:
				log.error('There is already something at the output directory path "%s"' % args.outputdir)
				sys.exit(1)
		# read user Real Name and email from dokuwiki
		self.read_user_data()

		# collect history
		# go through meta/ and media_meta/ *.changes to collect the change history
		# if "detect external edit" is set, also go through pages/ and media/ for latest version not recorded
		self.read_meta()
		if args.external_edit:
			self.read_pages_and_media()
		self.changelog.sort()
		
		# build commands
		if not os.path.exists(args.outputdir):
			self.commands.append('git init --quiet')
			self.commands.append('git config notes.displayRef %s' % self.shell_quote(self.args.notes_ref))
			self.commands.append('git config notes.rewriteRef %s' % self.shell_quote(self.args.notes_ref))
		# for each change history collected, find the corresponding history data file and build the import commands
		self.read_attic()
		# check the attic/ and media_attic/ for data files not recorded in the change history
		self.check_attic()
		# add a note for importing
		self.commands.append('git commit --quiet --allow-empty --author="dokuwiki2git <dokuwiki2git@hoxu.github.com>" -m "Dokuwiki data imported by dokuwiki2git"')

		# start running the shell commands
		log.info('%d commands queued to be executed' % len(self.commands))
		self.create_git_repository()

		# success, calculate and show the time spent
		time_end = time.time()
		time_took = time_end - time_start
		log.info('Finished converting dokuwiki "%s" into a git repository "%s", took %.2f seconds' % (args.dwdir, self.args.outputdir, time_took))

	def shell_quote(self, str):
		return "'" + str.replace("'", "'\\''") + "'"

if __name__ == '__main__':
	c = Converter()
	c.run(sys.argv[1:])
